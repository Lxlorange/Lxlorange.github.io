---
title: 分治策略
author: 凉香栾
date: 2025-07-23 15:27:16 +0800
categories:
  - 算法
tags:
  - 分治
  - 笔记
description: M210004B《算法设计与分析》学习笔记，第二章。
toc: true
pin: false
math: true
mermaid: true
comment: true
media_subpath: /assets/img/分治策略/
image:
  path: cover.jpg
  lqip: 
  alt: 分治策略
---

分治策略是一种强大而通用的算法设计范式。其核心思想是将一个难以直接解决的大问题，**分割**成两个或多个规模较小但形式与原问题相同的子问题，**递归地解决**这些子问题，然后将子问题的解**合并**以得到原问题的解。

这个过程可以概括为三个步骤：

1.  **分解 (Divide)**：将原问题分解为若干个规模较小、相互独立、且与原问题形式相同的子问题。
2.  **解决 (Conquer)**：若子问题规模足够小，则直接求解。否则，递归地调用算法解决这些子问题。
3.  **合并 (Combine)**：将各个子问题的解合并，构成原问题的解。

## 二分查找 (Binary Search)

二分查找是体现分治思想的一个经典算法。它用于在**有序数组**中高效地查找一个给定的键值。

> **问题描述**：给定一个按升序排列且各项互异的数组和一个键值 ，设计一个算法，如果键值在数组中，则返回其索引；否则，返回一个表示查找失败的特殊值（例如 -1）。

二分查找的分治策略如下：

1.  **分解 (Divide)**：选取数组的中间位置 $m = \lfloor(1+n)/2\rfloor$，将 $K$ 与中间元素 $A[m]$ 进行比较。这次比较将问题分解为三个可能的方向，但我们只需要选择其中一个方向继续，从而将问题规模缩减近一半。
2.  **解决 (Conquer)**：
      * 如果 $K = A[m]$，则查找成功，直接返回索引 $m$。
      * 如果 $K \lt A[m]$，则原问题转化为在左子数组 $A[1..m-1]$ 中查找 $K$ 的子问题。
      * 如果 $K \gt A[m]$，则原问题转化为在右子数组 $A[m+1..n]$ 中查找 $K$ 的子问题。
3.  **合并 (Combine)**：该算法的合并步骤是隐式的。因为在解决子问题时直接返回了结果，所以不需要额外的合并操作。

### 伪代码
**递归版：**

```
Algorithm FIND(A, low, high, K)
输入: 有序数组 A，查找范围的下界 low 和上界 high，键值 K
输出: 如果 K 在 A[low..high] 中则返回其索引; 否则返回 -1

1. if low > high then return -1
2. else
3.   mid ← floor((low + high) / 2)
4.   if K = A[mid] then return mid
5.   else if K < A[mid] then
6.     return FIND(A, low, mid - 1, K)
7.   else
8.     return FIND(A, mid + 1, high, K)
```

**循环版：**

```
Algorithm BinarySearch(A, n, K)
输入: 有序数组 A[1..n]，键值 K
输出: 如果K在A中则返回它的索引; 否则返回 -1

1. low ← 1, high ← n
2. while low ≤ high do
3.   mid ← floor((low + high) / 2)
4.   if K = A[mid] then return mid
5.   else if K < A[mid] then high ← mid – 1
6.   else low ← mid + 1
7. return -1
```

### 复杂度分析

我们以关键比较次数作为时间复杂度的度量。
* **最佳情况**：一次比较就找到，即 $K$ 恰好是数组的中间元素。复杂度为 $C_{best}(n) = 1$ 。
* **最差情况**：每次比较都未命中，直到子数组为空。其比较次数 $C_w(n)$ 的递推关系式为：

$$C_w(n) = 1 + C_w(\lfloor n/2 \rfloor), \quad \text{其中 } C_w(1) = 1$$

设 $n=2^k$。递推关系式变为 $C_w(2^k) = 1 + C_w(2^{k-1})$。
我们可以通过迭代展开来求解：

$$
\begin{align*}
C_w(2^k) &= 1 + C_w(2^{k-1}) \\
&= 1 + (1 + C_w(2^{k-2})) = 2 + C_w(2^{k-2}) \\
&= \dots \\
&= i + C_w(2^{k-i})
\end{align*}
$$

当 $i=k-1$ 时，我们得到 $C_w(2^k) = (k-1) + C_w(2)$。由 $C_w(2) = 1 + C_w(1) =2$，可得 $C_w(2^k) = k+1$。因为 $n=2^k$，所以$C_w(n) = \log_2 n + 1$。

对于一般的 $n$，解为 $C_w(n) = \lfloor \log_2 n \rfloor + 1$，也可以写作 $\lceil \log_2 (n+1) \rceil$ 。复杂度为 $\Theta(\log n)$。

* **平均情况 (成功查找)**：
我们可以将二分查找的过程看作一棵二叉决策树。对于一个包含 $n=2^k-1$ 个元素的完美平衡树，需要 $i$ 次比较才能找到的元素有 $2^{i-1}$ 个。
所有成功查找的平均比较次数为：

$$
A(n) = \frac{1}{n} \sum_{i=1}^{k} i \cdot 2^{i-1} = \frac{(k-1)2^k+1}{n} = \frac{(\log_2(n+1)-1)(n+1)+1}{n} \approx \log_2(n+1) - 1
$$

因此，平均情况下的时间复杂度也为 $\Theta(\log n)$。

### 例题与证明

**有序环上的最大值**：如果十二个互不相同的数，按照值大小，有序地排成一个环（但是不知道顺时针是升序还是降序，也不知道环的起点和终点在哪里）。如何找出这十二个数中的最大值？

**证明与解法**：
这个问题可以看作是在一个“旋转排序数组”中寻找最大值。这个问题依然可以用分治策略，通过修改二分查找来解决。
1.  **分解**：选择查找范围 `[low, high]` 的中间元素 `mid`。最大值是数组中唯一一个比它左右两边邻居都大的元素（在环状结构中，邻居索引需要取模计算）。
2.  **解决**：比较 $A[mid]$ 和它右边的邻居 $A[mid+1]$。
	  * 如果 $A[mid] \gt A[mid+1]$，说明 $A[mid]$ 可能就是最大值，或者最大值在它左边的“上坡”部分。因此，我们将问题规模缩小到左半部分 `[low, mid]`。
	  * 如果 $A[mid] \lt A[mid+1]$，说明从 $A[mid]$ 到 $A[mid+1]$ 是“上坡”，真正的最大值一定在右边的部分。因此，我们将问题规模缩小到右半部分 `[mid+1, high]`。
3.  **合并**：递归地执行上述过程，每次都将搜索空间减半。当 `low == high` 时，就找到了最大值。
	这个过程本质上是在用二分查找寻找数组中的“峰顶”，其时间复杂度为 $\Theta(\log n)$。对于12个数，只需要进行少量比较即可找到最大值。


## 允许“撒谎”的猜数游戏

> **猜数游戏问题描述**：甲从 $1$ 到 $n$ 之间选择一个整数 $x$，不告诉乙。乙进行猜测，甲会诚实地回答“猜中了”、“猜大了”或“猜小了” 。乙采用何种策略，才能保证在最坏情况下，用最少的次数猜中 $x$ ？

这个过程本质上构建一棵**二叉查找树**。为了让最坏情况下的猜测次数最少，需要让这棵树的高度尽可能小，也就是让它成为一棵**平衡二叉树** 。

对于 $n$ 个数，最坏情况下的猜测次数等于这棵平衡二叉查找树的高度。对于包含 $N$ 个节点的二叉树，其最小高度为 $\lfloor \log_2 N \rfloor$。因此，对于 $1$ 到 $n$ 的数字，最坏情况下的猜测次数为 $\lfloor \log_2 n \rfloor + 1$ 或 $\lceil\log_2(n+1)\rceil$ 。

这很简单，但我们可以引入一个新的条件，即甲可以“撒谎”。为了让问题不至于无解，乙提出两个约束：

> 1.  甲可以“撒谎”，但不能连续两次都撒谎。
> 2.  如果乙能将嫌疑范围缩小到不多于3个元素，甲就不再撒谎。

**解法与证明**：
这个问题需要更巧妙的分治策略来对抗“谎言”。

* **终止情况**：当嫌疑数少于或等于3个时，根据**约束2**，甲方不再撒谎。此时问题退化为标准的是/否猜数游戏，对于3个数，最多再提问2次即可确定。
* **递归步骤**：当嫌疑数大于3个时，乙方不能再简单地二分，于是可以将当前的嫌疑集合 $A$ （几乎）等分为4个子集 $A_1, A_2, A_3, A_4$ 。然后连续提出两个问题：
	1.  “你选的元素在 $A_1 \cup A_2$ 里面吗？”
	2.  “你选的元素在 $A_1 \cup A_3$ 里面吗？”

由于甲方最多只能对其中一个问题撒谎（因为问题是连续提出的），根据两次回答的组合（是/是，是/否，否/是，否/否），我们可以排除掉至少一个子集（即1/4的嫌疑数）。例如，如果两次都回答“是”，那么有三种可能：
1\.  两次都诚实：$x \in (A_1 \cup A_2)$ 且 $x \in (A_1 \cup A_3) \implies x \in A_1$。
2\.  第一次撒谎，第二次诚实：$x \in (A_3 \cup A_4)$ 且 $x \in (A_1 \cup A_3) \implies x \in A_3$。
3\.  第一次诚实，第二次撒谎：$x \in (A_1 \cup A_2)$ 且 $x \in (A_2 \cup A_4) \implies x \in A_2$。
无论如何，$x$ 肯定不在 $A_4$ 中。通过分析所有情况，可以证明两次提问总能将嫌疑范围缩小到原来的 $3/4$。

**复杂度分析**：
用 $T(n)$ 表示有 $n$ 个嫌疑数时猜中的最坏次数上限。我们得到递推关系式：

$$T(n) = \begin{cases} T(\lceil \frac{3}{4}n \rceil) + 2 & \text{若 } n > 3 \\ \le 2 & \text{若 } n \le 3 \end{cases}$$

该递推关系的解近似为 $T(n) \approx 2 \log_{4/3} n \approx 4.82 \log_2 n$ 。这说明，即使允许撒谎，我们依然有高效的分治策略来解决问题。

{% capture proof_content %}

断言：如果约束变为“甲不能连续 `a` 次都撒谎”，那么通过设计一个包含 **`a` 个问题**的“一轮”提问，我们确实可以保证每次都将嫌疑范围**精确地排除掉 $1/2^a$**。

**证明：**
为了对抗这种撒谎模式，我们将当前所有的嫌疑数集合 $S$（大小为 $n$）平均分为 $2^a$ 个子集，即 $S_1, S_2, \dots, S_{2^a}$。然后，我们设计 `a` 个问题，并将它们作为一轮，连续向甲提出，并从甲那里得到了一个答案序列，称之为**实际回答 R**。

我们想知道哪个子集可以被**绝对排除**。考虑一下与**实际回答 R** 完全相反的那个答案序列，我们称之为 $\bar{R}$（即把所有“是”换成“否”，所有“否”换成“是”）。如果 $x$ 恰好位于对应 $\bar{R}$ 的那个子集里，那么意味着 $\bar{R}$ 就是**真实答案**。为了让乙听到**实际回答 R**，甲就必须把真实答案 $\bar{R}$ 的每一位都颠倒过来。这需要甲在**连续的 `a` 个问题上，每一次都撒了谎**。根据我们的约束“甲不能连续 `a` 次都撒谎”，这种情况是不可能发生的。因此，我们可以**百分之百地确定**，$x$ 不在与 $\bar{R}$ 对应的那个子集里。

这就意味着，我们成功地从 $2^a$ 个子集中排除了一个。所以，嫌疑范围被精确地缩小了 $1/2^a$。

这样一来，每轮提问成本是`a` 次，问题规模缩小比例从 $n$ 变为 $n \cdot (1 - \frac{1}{2^a})$。因此，该策略的递推关系式为：

$$T(n) = T\left(n \cdot \frac{2^a - 1}{2^a}\right) + a$$

{% endcapture %} {% include components/collapsible.html title="扩展到连续说谎a次" content=proof_content %}

## 模幂运算 (Modular Exponentiation)

模幂运算在密码学等领域有重要应用。直接计算 $a^k$ 再取模，当 $a$ 和 $k$ 很大时，中间结果会超出计算机的表示范围，因此不可行。我们需要一个边计算边取模的高效算法。

> **问题描述**：给定整数 $a, k, n$（其中 $k \ge 0, n \ge 2$），计算 $a^k \pmod n$ 

该算法的核心思想是利用 $k$ 的二进制表示。任何一个整数 $k$ 都可以写成 $k = \sum_{i=0}^t k_i 2^i$，其中 $k_i \in {0, 1}$ 是 $k$ 的二进制表示的第 $i$ 位。
因此，$a^k = a^{\sum k_i 2^i} = \prod_{i=0}^t a^{k_i 2^i}$。由于 $k_i$ 只取0或1，这个连乘积只包含那些 $k_i=1$ 的项。

### 方案1：从左到右二进制法 (Left-to-Right Binary Method)

这种方法从 $k$ 的二进制表示的最高位开始处理，递推地计算幂。

 - 如果 $k$ 是偶数，则 $a^k = (a^{k/2})^2$。
 - 如果 $k$ 是奇数，则 $a^k = a \cdot (a^{(k-1)/2})^2$。

这个过程可以看作，从左到右扫描 $k$ 的二进制位。遇到一个比特位，就将当前的结果平方；如果该比特位是1，则再额外乘以一个 $a$。

 **伪代码**：

```
Algorithm Modular_Exp_Left_to_Right(a, k, n)
输入: 整数 a, k=(kt...k0)₂, n
输出: a^k (mod n)

1. A ← 1
2. for i from t downto 0 do
3.   A ← (A * A) mod n    // 平方
4.   if kᵢ = 1 then
5.     A ← (A * a) mod n  // 乘 a
6. return A
```

  **复杂度分析**：`for` 循环的次数为 $t+1 = \lfloor \log_2 k \rfloor + 1$。循环内部是常数次模乘法。因此，总的乘法次数为 $\lfloor \log_2 k \rfloor$ (平方操作) 和 $c(k)$ (乘a操作)之和，其中 $c(k)$ 是 $k$ 的二进制表示中1的个数。总复杂度为 $\Theta(\log k)$。

### 方案2：从右到左二进制法 (Right-to-Left Binary Method)

这种方法基于 $a^k = \prod_{k_i=1} a^{2^i}$，它从 $k$ 的最低位开始处理。

我们维护两个变量：一个是累积的乘积 `A`（初值为1），另一个是 $a$ 的幂次项 `b`（初值为 $a$）。从右到左遍历 $k$ 的二进制位 $k_0, k_1, \dots$。在第 $i$ 步：
  * 如果 $k_i=1$，则将当前的 $b=a^{2^i}$ 乘入累积结果 $A$ 中。
  * 无论 $k_i$ 是0还是1，都将 $b$ 更新为其自身的平方（$b \leftarrow b^2$），为下一步计算 $a^{2^{i+1}}$ 做准备。

**伪代码**：

```
Algorithm Modular_Exp_Right_to_Left(a, k, n)
输入: 整数 a, k=(kt...k0)₂, n
输出: a^k (mod n)

1. A ← 1
2. b ← a mod n
3. for i from 0 to t do
4.   if kᵢ = 1 then
5.     A ← (A * b) mod n
6.   b ← (b * b) mod n
7. return A
```

**复杂度分析**：`for` 循环的次数同样是 $\lfloor \log_2 k \rfloor + 1$。循环内最多有两次模乘法。因此，总复杂度也为 $\Theta(\log k)$ 。

两种方法的时间复杂度同阶，都是解决模幂问题的标准高效算法。它们完美地体现了分治思想：通过利用指数 $k$ 的二进制结构，将一个大的幂运算问题分解为一系列的平方和乘法操作。

## 归并排序 (Merge Sort)

归并排序是由数学家约翰·冯·诺伊曼（Jon von Neumann）于1945年发明的。排序算法在数据压缩、计算机图形学、生物学等众多领域都有着复杂而重要的应用。

> **问题描述**：给定一个包含 $n$ 个元素的序列 $S$，输出一个包含相同元素但已按非递减顺序排列的序列。

归并排序严格遵循分治范式：
1.  **分 (Divide)**：将包含 $n$ 个元素的序列 $S$ 分解为两个各含约 $n/2$ 个元素的子序列 $S_{1}$ 和 $S_{2}$。
2.  **治 (Conquer)**：递归地调用归并排序，对子序列 $S_{1}$ 和 $S_{2}$分别进行排序。
3.  **归并 (Combine)**：将两个已排序的子序列  $S_{1}$ 和 $S_{2}$ 合并（Merge），形成一个最终有序的序列 $S$。

 **伪代码**
 
```
Algorithm mergeSort(S)
输入: 长度为n的序列S
输出: S排序后的结果

1. if S.size() > 1 then
2.   (S₁, S₂) ← partition(S) // 将S分为两个子序列
3.   mergeSort(S₁)         // 递归排序S₁
4.   mergeSort(S₂)         // 递归排序S₂
5.   S ← merge(S₁, S₂)     // 合并已排序的S₁和S₂
```


#### 归并（Merge）子过程

算法的核心在于 `merge` 步骤，即如何高效地将两个已排序的序列合并为一个。

  * **方法**：使用一个临时的辅助数组。设置两个指针，分别指向两个已排序子序列的起始位置。
  * **流程**：
    1.  比较两个指针指向的元素，将较小的元素复制到辅助数组中，并将该指针后移一位。
    2.  重复此过程，直到其中一个子序列的所有元素都被处理完毕。
    3.  将另一个子序列中剩余的元素直接复制到辅助数组的末尾。
    4.  最后，将辅助数组中的所有元素复制回原数组的相应位置。
  * **复杂度**：对于总共 n 个元素，归并过程需要进行的比较次数最多为 n-1 次，数据移动次数为 2n（从原数组到辅助数组，再从辅助数组拷回）。因此，归并操作的时间复杂度是线性的，即 $\Theta(n)$.

#### **复杂度分析**

令 $T(n)$ 为归并排序对 n 个元素进行排序所需的比较次数。

  * **分解**：将数组一分为二的操作仅需计算中点索引，时间为 $\Theta(1)$。
  * **解决**：递归解决两个规模为 $n/2$ 的子问题，时间为 $2T(n/2)$。
  * **合并**：合并 n 个元素需要 $\Theta(n)$ 的时间。

综合起来，我们得到归并排序的递推关系式：

$$T(n) = 2T(n/2) + \Theta(n)$$

基准情况为 $T(1) = 0$。

使用下一节将要介绍的**主定理**可以解得：

$$T(n) \in \Theta(n \log_2 n)$$

## 主定理 (Master Theorem)

许多分治算法的递推关系式都遵循一种通用模式，使得我们可以用一个“菜谱”式的方法直接求出其时间复杂度，这个强大的工具就是**主定理 (Master Theorem)**。

### 递推关系式的通用形式

主定理适用于形如下式的递推关系：

$$T(n) = aT(n/b) + f(n)$$

其中：

  * $n$ 是问题规模。
  * $a$ 是递归调用的子问题数量（$a \ge 1$）。
  * $n/b$ 是每个子问题的规模（$b > 1$）。
  * $f(n)$ 是分解问题和合并子问题解所花费的时间。

### 简化的主定理

当合并成本函数 $f(n)$ 是一个简单的多项式，即 $f(n) = \Theta(n^d)$ 时，我们可以使用一个简化的主定理。

**定理**：给定递推关系 $T(n) = aT(n/b) + \Theta(n^d)$，其中 $a \ge 1, b > 1, d \ge 0$ ，则其解为：

1.  **若 $d > \log_b a$**：$T(n) \in \Theta(n^d)$ 。
2.  **若 $d = \log_b a$**：$T(n) \in \Theta(n^d \log n)$ 。
3.  **若 $d < \log_b a$**：$T(n) \in \Theta(n^{\log_b a})$ 。

**直观理解**：该定理比较的是“根节点（合并）的代价” ($n^d$) 与“叶子节点（递归累积）的代价” ($n^{\log_b a}$) 的大小。最终的复杂度由这两者中增长更快的一方决定。如果两者增长速度相当，则需要额外乘上一个对数因子 $\log n$。

### 主定理应用示例

| 算法名称             | 递推式                    | 参数 $(a, b, d)$  | $\log_b a$              | 时间复杂度                                           |
| ---------------- | ---------------------- | --------------- | ----------------------- | ----------------------------------------------- |
| **二分查找**         | $T(n) = T(n/2) + 1$    | $a=1, b=2, d=0$ | $0$                     | $\Theta(\log n)$                                |
| **归并排序**         | $T(n) = 2T(n/2) + n$   | $a=2, b=2, d=1$ | $1$                     | $\Theta(n \log n)$                              |
| **Karatsuba 乘法** | $T(n) = 3T(n/2) + n$   | $a=3, b=2, d=1$ | $\log_2 3 \approx 1.58$ | $\Theta(n^{\log_2 3}) \approx \Theta(n^{1.58})$ |
| **Strassen 乘法**  | $T(n) = 7T(n/2) + n^2$ | $a=7, b=2, d=2$ | $\log_2 7 \approx 2.81$ | $\Theta(n^{\log_2 7}) \approx \Theta(n^{2.81})$ |


### 其他形式的递推式

并非所有递归算法都遵循分治的 $T(n/b)$ 形式。一些算法（有时被称为 **减治法**）的递推关系为：

$$
T(n) = aT(n - 1) + O(1), \quad a \ge 1
$$

通过迭代展开可得：若 $a = 1$，解为 $T(n) \in O(n)$（线性复杂度）；若 $a > 1$，解为 $T(n) \in O(a^n)$（指数复杂度）。

## 大数乘法 (Large Integer Multiplication)

对于超出标准数据类型（如64位整数）表示范围的大数，其算术运算需要通过专门的算法实现。

#### **基础：大数加法**

* **问题**：计算两个 n 比特长的二进制整数的和 。
* **算法**：采用经典的“小学生”加法，从最低位开始逐位相加，并处理进位 。
* **复杂度与证明**：
    * 每一位的计算（两个比特和来自前一位的进位相加）都可以在常数时间内完成 。
    * 对于 n 位数，这个过程需要重复 n 次，因此总时间复杂度为 $\Theta(n)$ 。
    * 该算法是**渐进最优**的，因为任何加法算法都必须至少读取所有输入的 $2n$ 个比特才能保证结果的正确性，所以其时间复杂度的下界也是 $\Omega(n)$ 。

#### **“小学生”乘法**

* **问题**：计算两个 n 比特长的整数 X 和 Y 的乘积 。
* **算法**：传统的长乘法，包括 n 次“乘以单个数位并移位”的操作和 n-1 次加法操作。
* **复杂度**：该过程涉及到约 $n^2$ 次比特级别的乘法和加法，因此总时间复杂度为 $\Theta(n^2)$ 。

#### **分治策略：Karatsuba 算法**

能否设计出比 $\Theta(n^2)$ 更快的乘法算法？答案是肯定的。

**1. 初次尝试（朴素分治）**

* **分解**：将一个 n 比特的整数 X 分为两个 n/2 比特的部分，高位 a 和低位 b，即 $X = a \cdot 2^{n/2} + b$ 。
同样地，$Y = c \cdot 2^{n/2} + d$ 。
* **计算**：两数之积为：
    $$XY = (a \cdot 2^{n/2} + b)(c \cdot 2^{n/2} + d) = (ac) \cdot 2^n + (ad+bc) \cdot 2^{n/2} + bd$$ 
* **分析**：这个公式需要进行**4次** n/2 比特的乘法（$ac, ad, bc, bd$）以及若干次线性时间的加法和移位操作 。其递推关系式为：
    $$T(n) = 4T(n/2) + \Theta(n)$$ 
    根据主定理（$a=4, b=2, d=1$），$\log_b a = \log_2 4 = 2 > d$。解为 $T(n) = \Theta(n^{\log_2 4}) = \Theta(n^2)$ 。
    这个朴素的分治算法和“小学生”乘法一样慢，没有带来任何改进 。

**2. Karatsuba 算法 (1962)**

* **核心技巧**：Karatsuba 发现，中间项 $(ad+bc)$ 并不需要两次独立的乘法来计算。这个技巧的灵感来源于高斯计算复数乘法的方法 。
    $$ad+bc = (a+b)(c+d) - ac - bd$$
    
* **算法流程**：
    1.  递归计算 $e = ac$。
    2.  递归计算 $f = bd$。
    3.  计算 $a+b$ 和 $c+d$，然后递归计算 $g = (a+b)(c+d)$。
    4.  通过 $g - e - f$ 得到中间项 $(ad+bc)$。
    5.  最终结果为 $e \cdot 2^n + (g - e - f) \cdot 2^{n/2} + f$ 。
* **分析**：
    这个过程只需要**3次** n/2 比特（或 n/2+1 比特）的乘法 。其递推关系式变为：
    
    $$T(n) = 3T(n/2) + \Theta(n)$$
     
    根据主定理（$a=3, b=2, d=1$），$\log_b a = \log_2 3 \approx 1.58 > d$。解为 $T(n) = \Theta(n^{\log_2 3}) \approx \Theta(n^{1.58})$ 。
    这是一个显著的改进，证明了我们可以做得比 $\Theta(n^2)$ 更好 。

## Strassen 矩阵乘法

与大数乘法类似，传统矩阵乘法也可以通过分治策略进行优化。

#### **“教科书”矩阵乘法**

* **问题**：计算两个 $n \times n$ 的方阵 A 和 B 的乘积 C=AB 。
* **算法**：根据定义 $c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}$ ，使用三层循环计算每个 $c_{ij}$。
* **复杂度**：该算法需要 $n^3$ 次乘法和 $n^2(n-1)$ 次加法，总时间复杂度为 $\Theta(n^3)$ 。

#### **分治策略：Strassen 算法**

**1. 初次尝试（朴素分治）**

* **分解**：将 $n \times n$ 矩阵 A, B, C 分别分解为 4 个 $n/2 \times n/2$ 的子矩阵 。
    
    $$\begin{pmatrix} C_{11} & C_{12} \\ C_{21} & C_{22} \end{pmatrix} = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix} \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}$$
    
* **计算**：$C_{11} = A_{11}B_{11} + A_{12}B_{21}$，以此类推，总共需要**8次** $n/2 \times n/2$ 规模的矩阵乘法和4次矩阵加法 。
* **分析**：递推关系式为 $T(n) = 8T(n/2) + \Theta(n^2)$ 。
    根据主定理（$a=8, b=2, d=2$），$\log_b a = \log_2 8 = 3 > d$。解为 $T(n) = \Theta(n^{\log_2 8}) = \Theta(n^3)$ 。同样，没有任何改进。

**2. Strassen 算法 (1969)** 

* **核心技巧**：Volker Strassen 发现，通过巧妙地构造7个中间矩阵的乘积，并对它们进行加减组合，可以只用**7次**递归的矩阵乘法和18次矩阵加减法来完成计算 。
    例如，其中一个结果块 $C_{12}$ 可以通过 $R+T$ 计算得到，而 $R$ 和 $T$ 是通过以下方式预先计算的：
    * $R = A_{11} \times (B_{12}-B_{22})$
    * $T = (A_{11} + A_{12}) \times B_{22}$
* **分析**：
    该算法的递推关系式为：
    
    $$T(n) = 7T(n/2) + \Theta(n^2)$$
     
    根据主定理（$a=7, b=2, d=2$），$\log_b a = \log_2 7 \approx 2.81 > d$。解为：
    
    $$T(n) = \Theta(n^{\log_2 7}) \approx \Theta(n^{2.81})$$
     
* **意义**：Strassen 算法在理论和实践上都击败了 $\Theta(n^3)$ 的传统算法 。
虽然其实现较为复杂，且由于常数因子较大，只在矩阵规模较大时（例如 $n>128$）才体现出优势 ，但它开创了快速矩阵乘法研究的新纪元。


## 快速排序 (Quick Sort)

快速排序由 C.A.R. Hoare 于1962年提出，是实践中应用最广泛、效率最高的排序算法之一。它同样基于分治策略，但其精髓在于巧妙的“分解”步骤。 

#### **算法描述**

快速排序与归并排序的核心区别在于，它的主要工作集中在**分解 (Divide)**阶段，而**合并 (Combine)**阶段是平凡的。 

1.  **分 (Divide)**：
    * 从数组中选择一个元素作为**划分元**或**枢轴 (pivot)**。 
    * **划分 (Partition)** 数组：重新排列数组，使得所有小于枢轴的元素都移动到其左侧，所有大于枢轴的元素都移动到其右侧。枢轴最终会处在它在排序后应该在的最终位置。  
    这一步是快速排序的关键，必须在线性时间内完成。 
2.  **治 (Conquer)**：递归地对枢轴左侧和右侧的两个子数组调用快速排序。 
3.  **合 (Combine)**：无需任何操作。因为子数组都是在原数组上“就地”排序的，当递归结束时，整个数组自然有序。 

#### **划分 (Partition) 子过程**

划分操作有两种经典实现方法。

##### **1. 双边循环法**
* **流程**：
    1.  选择一个枢轴（例如第一个元素）。 
    2.  设置 `left` 和 `right` 两个指针，分别指向数组的第二个元素和最后一个元素。 
    3.  `right` 指针向左移动，直到找到一个小于枢轴的元素。 
    4.  `left` 指针向右移动，直到找到一个大于枢轴的元素。 
    5.  交换 `left` 和 `right` 指针指向的元素。 
    6.  重复步骤3-5，直到 `left` 和 `right` 指针相遇或交错。 
    7.  最后，将枢轴与 `right` 指针指向的元素交换。 

##### **2. 单边循环法 (Lomuto Partition Scheme)**
* **流程**：
    1.  选择一个枢轴（例如第一个元素）。
    2.  设置一个 `mark` 指针，指向枢轴的位置，它代表“小于枢轴”区域的右边界。 
    3.  用另一个指针从左到右遍历数组。
    4.  如果遍历到的元素小于枢轴，则先将 `mark` 指针右移一位，然后交换 `mark` 指针和当前遍历指针所指向的元素。 
    5.  遍历结束后，将枢轴与 `mark` 指针指向的元素交换。 

#### **复杂度分析**

* **最差情况**：当每次选择的枢轴都是当前子数组的最小值或最大值时发生。这通常出现在数组已经有序（或逆序）且总是选择第一个元素为枢轴的情况下。 
    * 划分将产生一个空的子数组和一个大小为 $n-1$ 的子数组。 
    * 递推关系式为：$T(n) = T(n-1) + \Theta(n)$。 
    * 解为 $T(n) = \Theta(n^2)$。 
* **最佳情况**：当每次选择的枢轴都恰好是中位数，能将数组完美地划分为两个大小相等的子数组。 
    * 递推关系式为：$T(n) = 2T(n/2) + \Theta(n)$。 
    * 解为 $T(n) = \Theta(n \log n)$，与归并排序相同。 
* **平均情况**：可以证明，即使划分不完全均衡，只要是常数比例的划分，其平均时间复杂度依然是 $\Theta(n \log n)$。 

#### **优化：随机化**
为了避免最坏情况的发生，可以采用**随机化**策略：每次不选择固定位置的元素，而是在当前子数组中**随机选择**一个元素作为枢轴。  
这样可以使得最坏情况的划分在任何输入下都变得极不可能，使得算法的期望运行时间为 $\Theta(n \log n)$。 

---

## 选择问题 (The Selection Problem)

选择问题是另一个可以用分治法高效解决的经典问题。

#### **问题定义**

给定一个由 n 个互异元素组成的集合 S 和一个整数 $k$（$1 \le k \le n$），找到 S 中第 k 小的元素。 
* 当 $k=1$ 时，是找最小值。 
* 当 $k=n$ 时，是找最大值。 
* 当 $k=\lceil n/2 \rceil$ 时，是找**中位数 (median)**。 

#### **基于排序的解法**

最直接的方法是对集合 S 进行排序，然后返回第 k 个元素。  
使用归并排序等最优算法，时间复杂度为 $\Theta(n \log n)$。  
但我们的目标是找到一个线性时间的算法。 

#### **随机化选择算法 (Quickselect)**

该算法的思路与快速排序非常相似，但更高效，因为它只处理其中一个子问题。

* **算法流程**：
    1.  **分解**：从集合 S 中**随机**选择一个元素 x 作为枢轴。 
    2.  **划分**：以 x 为枢轴将 S 划分为两个子集：$S_< = \\{ y \in S \| y < x \\}$ 和 $S_> = \\{ y \in S \| y > x \\}$。这个过程需要 $\Theta(n)$ 时间。 
    3.  **解决**：计算枢轴 x 的秩 $R(x, S) = \|S_<\| + 1$。
        * 如果 $R(x, S) = k$，则 x 就是要找的元素。 
        * 如果 $R(x, S) > k$，则第 k 小的元素在 $S_<$ 中，递归地在 $S_<$ 中寻找第 k 小的元素。 
        * 如果 $R(x, S) < k$，则第 k 小的元素在 $S_>$ 中，递归地在 $S_>$ 中寻找第 $k - R(x, S)$ 小的元素。 

* **复杂度分析**：
    * **最差情况**：与快速排序一样，如果每次都选到最差的枢轴，复杂度为 $\Theta(n^2)$。 
    * **期望（平均）情况**：由于每次只递归进入一个子问题，递推关系式为 $T(n) \le T(3n/4) + \Theta(n)$（假设我们能找到一个“好的”枢轴，将问题规模至少缩减1/4）。  
    该递推式的解为 $T(n) = \Theta(n)$。 

#### **确定性线性时间算法 (中位数的中位数)**

Blum、Floyd、Pratt、Rivest 和 Tarjan 在1973年提出了一个巧妙的确定性算法，确保在最坏情况下也能达到线性时间复杂度。 
* **核心思想**：设计一个方法来确定性地找到一个“好的”枢轴，保证划分是足够平衡的。 
* **“中位数的中位数”枢轴选择**：
    1.  将 n 个元素划分为 $\lceil n/5 \rceil$ 组，每组5个元素。 
    2.  对每组（5个元素）进行排序，找到该组的中位数。这一步总共耗时 $\Theta(n)$。 
    3.  **递归地**调用选择算法，在这 $\lceil n/5 \rceil$ 个中位数中找到它们的中位数 M。 
    4.  使用 M 作为枢轴来划分整个数组。 
* **证明与分析**：
    * 可以证明，通过这种方法选出的枢轴 M，其秩 $R(M, S)$ 必然满足 $3n/10 \le R(M, S) \le 7n/10$。  
    这保证了每次划分后，问题规模最大为原先的 $7/10$。 
    * 算法的递推关系式为：$T(n) \le T(\lceil n/5 \rceil) + T(7n/10) + \Theta(n)$。 
    * 因为 $1/5 + 7/10 = 9/10 < 1$，可以证明该递推式的解为 $T(n) = \Theta(n)$。 

---

## 平面最近点对问题 (Closest Pair of Points)

这是一个经典的计算几何问题，分治策略在此也表现出强大的威力。

#### **问题定义**

给定平面上的 n 个点，找到其中欧氏距离最小的一对点。 

#### **朴素解法与一维情况**

* **朴素解法（蛮力法）**：计算所有 $\binom{n}{2}$ 对点之间的距离，找出最小值。时间复杂度为 $\Theta(n^2)$。 
* **一维情况**：如果所有点都在一条直线上，可以先对点进行排序，然后只需遍历一次，比较所有相邻点对的距离即可。时间复杂度由排序主导，为 $\Theta(n \log n)$。 

#### **分治算法**

1.  **预处理**：为了达到最优效率，首先将所有点按 x 坐标和 y 坐标分别排序，得到两个列表 $P_x$ 和 $P_y$。此步骤耗时 $\Theta(n \log n)$。
2.  **分 (Divide)**：根据 $P_x$，找到一个垂直中线 L，将所有点平分为左右两个子集 $P_L$ 和 $P_R$，每个子集约有 $n/2$ 个点。 
3.  **治 (Conquer)**：递归地在 $P_L$ 和 $P_R$ 中寻找最近点对，得到两个最小距离 $\delta_L$ 和 $\delta_R$。 
4.  **合 (Combine)**：这是算法最关键的一步。最近点对可能是 $(\text{点} \in P_L, \text{点} \in P_L)$，也可能是 $(\text{点} \in P_R, \text{点} \in P_R)$，还可能是跨越中线 L 的一对点 $(\text{点} \in P_L, \text{点} \in P_R)$。
    * 令 $\delta = \min(\delta_L, \delta_R)$。 
    * 我们只需寻找是否存在一个跨越中线的点对，其距离小于 $\delta$。 
    * **关键优化**：任何这样的跨越点对，其两个点与中线 L 的水平距离都必须小于 $\delta$。因此，我们只需考虑一个以 L 为中心、宽度为 $2\delta$ 的垂直条带区域内的点。 
    * **最终证明**：将此条带内的点按 y 坐标排序。可以证明，对于此有序列表中的任意一点 $p$，我们**只需检查其后的常数个点**（可以证明最多11个，甚至可以优化到7个），就能找到可能与 $p$ 构成距离小于 $\delta$ 的所有点。  这是因为在 y 坐标方向上，任何相距超过 $\delta$ 的点对距离也必然大于 $\delta$。
5.  **复杂度分析**：
    * 通过在递归过程中巧妙地维护 y 坐标的排序，可以使合并步骤在 $\Theta(n)$ 时间内完成。 
    * 递推关系式为：$T(n) = 2T(n/2) + \Theta(n)$。 
    * 根据主定理，解为 $T(n) = \Theta(n \log n)$。
    * 加上预处理的时间，平面最近点对问题的总时间复杂度为 $\Theta(n \log n)$。

## 芯片测试问题 (The Chip Testing Problem)

#### **问题定义**

* **背景**：我们有 n 片芯片，其中一部分是**合格芯片**，另一部分是**劣质芯片** 。
* **核心约束**：已知合格芯片的数量**严格超过**总数的一半。也就是说，合格芯片比劣质芯片至少多1片 。
* **测试方法**：一次只能测试两片芯片。将它们放在一起互相测试，每片芯片都会对另一片报告一个结果：“合格”或“劣质” 。
    * **合格芯片**的报告总是**正确**的 。
    * **劣质芯片**的报告是**不可靠**的（可能正确也可能错误） 。
* **目标**：设计一个算法，用尽可能少的测试次数，从这 n 片芯片中找出1片合格的芯片 。

#### **测试结果分析**

当芯片 A 测试芯片 B 时，根据 A 和 B 的真实情况，所有可能的结果如下表所示 ：

| 芯片A真实情况 | 芯片B真实情况 | A对B的报告 | B对A的报告 | 结论 |
| :--- | :--- | :--- | :--- | :--- |
| 合格 | 合格 | 合格 | 合格 | A、B都可能是合格的 |
| 合格 | 劣质 | 劣质 | 不确定 | 至少有一个是劣质的 |
| 劣质 | 合格 | 不确定 | 劣质 | 至少有一个是劣质的 |
| 劣质 | 劣质 | 不确定 | 不确定 | 至少有一个是劣质的 |

关键的推论是：
> 如果两片芯片互相报告对方是“合格”的，那么它们要么都是合格的，要么都是劣质的。在任何其他报告情况下，这两片芯片中至少有一片是劣质的。

#### **蛮力算法**

一个简单的想法是任取一片芯片，让其余所有芯片都测试它 。
* **判断准则**：由于合格芯片占多数，如果一片芯片 X 是合格的，那么测试它的 $n-1$ 片芯片中，至少有 $\lceil n/2 \rceil - 1$ 片是合格的，所以 X 至少会收到 $\lceil n/2 \rceil - 1$ 个“合格”报告。反之，如果 X 是劣质的，它收到的“合格”报告数不会超过劣质芯片的总数，即小于 $n/2$。因此，如果一片芯片收到的“合格”报告数**大于等于** $\lceil (n-1)/2 \rceil$ (即一半以上)，它一定是合格的 。
* **流程**：随机选一片，测试完后判断。如果是合格的，则找到；如果是劣质的，就扔掉它，再选下一片 。
* **复杂度**：在最坏情况下（每次都先挑到劣质芯片），需要测试近 $n/2$ 片芯片，每片都需要约 $n-1$ 次测试，总复杂度为 $O(n^2)$ 。

#### **分治策略算法**

我们可以设计一个线性时间复杂度的分治算法。

* **核心思想**：将 n 片芯片两两配对进行测试。根据测试结果，我们可以安全地淘汰掉一部分芯片，同时保证 **“合格芯片是多数”** 这一性质在剩余的芯片中仍然成立，从而将问题规模减半。

* **算法步骤**：
    1.  **分解 (Divide)**：
        * 如果 n 是偶数，将芯片分为 $n/2$ 对。
        * 如果 n 是奇数，将其中 $n-1$ 片芯片分为 $(n-1)/2$ 对，剩下1片芯片单独放着。
    2.  **解决 (Conquer)**：对每一对芯片 (A, B) 进行一次互相测试。
        * **情况1**：如果A和B互相报告对方是“**合格**”，则保留其中**任意一片**（例如A），将另一片（B）丢弃。
        * **情况2**：如果测试结果是其他任何情况（例如，A报告B“劣质”，或B报告A“劣质”，或互相报告“劣质”），则将**这两片芯片全部丢弃** 。
    3.  **合并 (Combine)**：将每对中保留下来的芯片，以及那个在奇数情况下单独剩下的芯片，合并成一个新的集合。这个新集合的芯片数量最多为 $\lceil n/2 \rceil$。然后，对这个新的、规模更小的集合**递归地调用**本算法。
    4.  **基准情况**：当芯片数量 $n \le 2$ 时，由于合格芯片是多数，任取一片即为合格芯片，问题可直接解决（或者当 $n \le 4$ 时，用至多1次测试解决 ）。

* **算法正确性证明**：
    算法的关键在于每轮淘汰后，剩余芯片中合格芯片依然占多数。
    * 在情况1中（互相报告“合格”），这对芯片要么是（合格，合格），要么是（劣质，劣质） 。我们保留一片、丢弃一片。如果原来是（合格，合格），我们丢弃了一片合格芯片，合格芯片和劣质芯片总数各减一；如果原来是（劣质，劣质），我们丢弃了一片劣质芯片。
    * 在情况2中（其他报告），这对芯片中至少有一片是劣质的。我们将两片都丢弃。这会丢弃至少一片劣质芯片，至多一片合格芯片。
    
    只要丢弃的劣质芯片数量不少于合格芯片数量，那么“合格芯片比劣质芯片至少多1片”这个性质就不会改变 。我们的策略确保了这一点，因此算法的正确性得以保证。

* **复杂度分析**：
    设 $T(n)$ 为测试 $n$ 片芯片所需的测试次数。
    在分解步骤中，我们进行了 $\lfloor n/2 \rfloor$ 次测试。之后，问题规模缩小到最多 $\lceil n/2 \rceil$。因此，递推关系式为：
    
    $$T(n) = T(\lceil n/2 \rceil) + \lfloor n/2 \rfloor$$
    
    基准情况为 $T(c) = O(1)$（其中 $c$ 是一个小的常数，例如 $c \le 4$）。
    
    **证明**：
    我们可以通过迭代展开来求解该递推式（为简化，暂不考虑取整）：
    
    $$
    \begin{align*}
    T(n) &= T(n/2) + n/2 \\
    &= (T(n/4) + n/4) + n/2 \\
    &= (T(n/8) + n/8) + n/4 + n/2 \\
    &= T(1) + n/2 + n/4 + n/8 + \dots + 1 \\
    &= T(1) + n(1/2 + 1/4 + 1/8 + \dots)
    \end{align*}
    $$
    
    括号中的等比数列的和趋近于1。因此，$T(n) \approx n - 1$。
    所以，该分治算法的时间复杂度为 $\Theta(n)$ ，远优于蛮力算法的 $O(n^2)$。

